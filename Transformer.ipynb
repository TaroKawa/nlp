{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GrcYw69qwuM",
        "colab_type": "code",
        "outputId": "d5b30cfd-861a-4635-8c08-9ec123124fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ggDb2wtjp36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# フォルダ「data」が存在しない場合は作成する\n",
        "data_dir = \"./data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8KlPvwwjsQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word2vecの日本語学習済みモデル\n",
        "# 日本語対応を行うため\n",
        "\n",
        "url = \"http://www.cl.ecei.tohoku.ac.jp/~m-suzuki/jawiki_vector/data/20170201.tar.bz2\"\n",
        "save_path = \"./data/20170201.tar.bz2\"\n",
        "if not os.path.exists(save_path):\n",
        "    urllib.request.urlretrieve(url, save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZNNCylqjuwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tarファイルを読み込み\n",
        "tar = tarfile.open('./data/20170201.tar.bz2', 'r|bz2')\n",
        "tar.extractall('./data/')  # 解凍\n",
        "tar.close()  # ファイルをクローズ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MrrY-xcjzyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fastText for English\n",
        "url = \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\"\n",
        "save_path = \"./data/wiki-news-300d-1M.vec.zip\"\n",
        "if not os.path.exists(save_path):\n",
        "    urllib.request.urlretrieve(url, save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7IHVkMDj8tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip = zipfile.ZipFile(\"./data/wiki-news-300d-1M.vec.zip\")\n",
        "zip.extractall(\"./data/\")\n",
        "zip.close() \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBgHN5fbj_0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "save_path = \"./data/aclImdb_v1.tar.gz\"\n",
        "if not os.path.exists(save_path):\n",
        "    urllib.request.urlretrieve(url, save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H2sbgUOkCjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 今回はIMDBデータセットを使ってみる\n",
        "# tarファイルを読み込み\n",
        "tar = tarfile.open('./data/aclImdb_v1.tar.gz')\n",
        "tar.extractall('./data/')\n",
        "tar.close()  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B-aWbMkla5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# driveに存在するvetor_neologdをgoogle colabで使えるようにする\n",
        "zip = zipfile.ZipFile(\"./drive/My Drive/vector_neologd.zip\")\n",
        "zip.extractall(\"./data/vector_neologd/\")  \n",
        "zip.close()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hmblqp8gg-d",
        "colab_type": "code",
        "outputId": "5d088eaa-4002-4675-d46a-7da69513d6ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# mecabとか\n",
        "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "curl is already the newest version (7.58.0-2ubuntu3.8).\n",
            "git is already the newest version (1:2.17.1-1ubuntu0.5).\n",
            "sudo is already the newest version (1.8.21p2-3ubuntu1.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libmagic-mgc libmagic1 libmecab2 mecab-ipadic mecab-jumandic\n",
            "  mecab-jumandic-utf8 mecab-utils\n",
            "The following NEW packages will be installed:\n",
            "  file libmagic-mgc libmagic1 libmecab-dev libmecab2 mecab mecab-ipadic\n",
            "  mecab-ipadic-utf8 mecab-jumandic mecab-jumandic-utf8 mecab-utils\n",
            "  python-mecab\n",
            "0 upgraded, 12 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 29.3 MB of archives.\n",
            "After this operation, 282 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.3 [184 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.3 [68.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.3 [22.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic-utf8 all 7.0-20130310-4 [16.2 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic all 7.0-20130310-4 [2,212 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic all 2.7.0-20070801+main-1 [12.1 MB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-1 [3,522 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-mecab amd64 0.99.6-2 [36.0 kB]\n",
            "Fetched 29.3 MB in 0s (58.9 MB/s)\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 135004 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.3) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.3) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.3) ...\n",
            "Selecting previously unselected package libmecab2:amd64.\n",
            "Preparing to unpack .../03-libmecab2_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab2:amd64 (0.996-5) ...\n",
            "Selecting previously unselected package libmecab-dev.\n",
            "Preparing to unpack .../04-libmecab-dev_0.996-5_amd64.deb ...\n",
            "Unpacking libmecab-dev (0.996-5) ...\n",
            "Selecting previously unselected package mecab-utils.\n",
            "Preparing to unpack .../05-mecab-utils_0.996-5_amd64.deb ...\n",
            "Unpacking mecab-utils (0.996-5) ...\n",
            "Selecting previously unselected package mecab-jumandic-utf8.\n",
            "Preparing to unpack .../06-mecab-jumandic-utf8_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-jumandic.\n",
            "Preparing to unpack .../07-mecab-jumandic_7.0-20130310-4_all.deb ...\n",
            "Unpacking mecab-jumandic (7.0-20130310-4) ...\n",
            "Selecting previously unselected package mecab-ipadic.\n",
            "Preparing to unpack .../08-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Selecting previously unselected package mecab.\n",
            "Preparing to unpack .../09-mecab_0.996-5_amd64.deb ...\n",
            "Unpacking mecab (0.996-5) ...\n",
            "Selecting previously unselected package mecab-ipadic-utf8.\n",
            "Preparing to unpack .../10-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n",
            "Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Selecting previously unselected package python-mecab.\n",
            "Preparing to unpack .../11-python-mecab_0.99.6-2_amd64.deb ...\n",
            "Unpacking python-mecab (0.99.6-2) ...\n",
            "Setting up libmecab2:amd64 (0.996-5) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.3) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.3) ...\n",
            "Setting up mecab-utils (0.996-5) ...\n",
            "Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up python-mecab (0.99.6-2) ...\n",
            "Setting up libmecab-dev (0.996-5) ...\n",
            "Setting up file (1:5.32-2ubuntu0.3) ...\n",
            "Setting up mecab-jumandic-utf8 (7.0-20130310-4) ...\n",
            "Compiling Juman dictionary for Mecab.\n",
            "reading /usr/share/mecab/dic/juman/unk.def ... 37\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/Emoticon.csv ... 972\n",
            "reading /usr/share/mecab/dic/juman/Noun.hukusi.csv ... 81\n",
            "reading /usr/share/mecab/dic/juman/Postp.csv ... 108\n",
            "reading /usr/share/mecab/dic/juman/AuxV.csv ... 593\n",
            "reading /usr/share/mecab/dic/juman/Noun.koyuu.csv ... 7964\n",
            "reading /usr/share/mecab/dic/juman/Noun.keishiki.csv ... 8\n",
            "reading /usr/share/mecab/dic/juman/Rengo.csv ... 1118\n",
            "reading /usr/share/mecab/dic/juman/Wikipedia.csv ... 167709\n",
            "reading /usr/share/mecab/dic/juman/ContentW.csv ... 551145\n",
            "reading /usr/share/mecab/dic/juman/Suffix.csv ... 2128\n",
            "reading /usr/share/mecab/dic/juman/Assert.csv ... 34\n",
            "reading /usr/share/mecab/dic/juman/Special.csv ... 158\n",
            "reading /usr/share/mecab/dic/juman/Auto.csv ... 18931\n",
            "reading /usr/share/mecab/dic/juman/Prefix.csv ... 90\n",
            "reading /usr/share/mecab/dic/juman/Demonstrative.csv ... 97\n",
            "reading /usr/share/mecab/dic/juman/Noun.suusi.csv ... 49\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/juman/matrix.def ... 1876x1876\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n",
            "Setting up mecab (0.996-5) ...\n",
            "Compiling IPA dictionary for Mecab.  This takes long time...\n",
            "reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n",
            "reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n",
            "reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n",
            "reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n",
            "reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n",
            "reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n",
            "reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n",
            "reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n",
            "reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n",
            "reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n",
            "reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n",
            "reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n",
            "reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n",
            "reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n",
            "reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "Setting up mecab-jumandic (7.0-20130310-4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Cloning into 'mecab-ipadic-neologd'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 75 (delta 5), reused 54 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (75/75), done.\n",
            "[install-mecab-ipadic-NEologd] : Start..\n",
            "[install-mecab-ipadic-NEologd] : Check the existance of libraries\n",
            "[install-mecab-ipadic-NEologd] :     find => ok\n",
            "[install-mecab-ipadic-NEologd] :     sort => ok\n",
            "[install-mecab-ipadic-NEologd] :     head => ok\n",
            "[install-mecab-ipadic-NEologd] :     cut => ok\n",
            "[install-mecab-ipadic-NEologd] :     egrep => ok\n",
            "[install-mecab-ipadic-NEologd] :     mecab => ok\n",
            "[install-mecab-ipadic-NEologd] :     mecab-config => ok\n",
            "[install-mecab-ipadic-NEologd] :     make => ok\n",
            "[install-mecab-ipadic-NEologd] :     curl => ok\n",
            "[install-mecab-ipadic-NEologd] :     sed => ok\n",
            "[install-mecab-ipadic-NEologd] :     cat => ok\n",
            "[install-mecab-ipadic-NEologd] :     diff => ok\n",
            "[install-mecab-ipadic-NEologd] :     tar => ok\n",
            "[install-mecab-ipadic-NEologd] :     unxz => ok\n",
            "[install-mecab-ipadic-NEologd] :     xargs => ok\n",
            "[install-mecab-ipadic-NEologd] :     grep => ok\n",
            "[install-mecab-ipadic-NEologd] :     iconv => ok\n",
            "[install-mecab-ipadic-NEologd] :     patch => ok\n",
            "[install-mecab-ipadic-NEologd] :     which => ok\n",
            "[install-mecab-ipadic-NEologd] :     file => ok\n",
            "[install-mecab-ipadic-NEologd] :     openssl => ok\n",
            "[install-mecab-ipadic-NEologd] :     awk => ok\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : mecab-ipadic-NEologd is already up-to-date\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : mecab-ipadic-NEologd will be install to /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Make mecab-ipadic-NEologd\n",
            "[make-mecab-ipadic-NEologd] : Start..\n",
            "[make-mecab-ipadic-NEologd] : Check local seed directory\n",
            "[make-mecab-ipadic-NEologd] : Check local seed file\n",
            "[make-mecab-ipadic-NEologd] : Check local build directory\n",
            "[make-mecab-ipadic-NEologd] : create /content/mecab-ipadic-neologd/libexec/../build\n",
            "[make-mecab-ipadic-NEologd] : Download original mecab-ipadic file\n",
            "[make-mecab-ipadic-NEologd] : Try to access to https://ja.osdn.net\n",
            "[make-mecab-ipadic-NEologd] : Try to download from https://ja.osdn.net/frs/g_redir.php?m=kent&f=mecab%2Fmecab-ipadic%2F2.7.0-20070801%2Fmecab-ipadic-2.7.0-20070801.tar.gz\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 11.6M  100 11.6M    0     0  1163k      0  0:00:10  0:00:10 --:--:-- 2457k\n",
            "Hash value of /content/mecab-ipadic-neologd/libexec/../build/mecab-ipadic-2.7.0-20070801.tar.gz matched\n",
            "[make-mecab-ipadic-NEologd] : Decompress original mecab-ipadic file\n",
            "mecab-ipadic-2.7.0-20070801/\n",
            "mecab-ipadic-2.7.0-20070801/README\n",
            "mecab-ipadic-2.7.0-20070801/AUTHORS\n",
            "mecab-ipadic-2.7.0-20070801/COPYING\n",
            "mecab-ipadic-2.7.0-20070801/ChangeLog\n",
            "mecab-ipadic-2.7.0-20070801/INSTALL\n",
            "mecab-ipadic-2.7.0-20070801/Makefile.am\n",
            "mecab-ipadic-2.7.0-20070801/Makefile.in\n",
            "mecab-ipadic-2.7.0-20070801/NEWS\n",
            "mecab-ipadic-2.7.0-20070801/aclocal.m4\n",
            "mecab-ipadic-2.7.0-20070801/config.guess\n",
            "mecab-ipadic-2.7.0-20070801/config.sub\n",
            "mecab-ipadic-2.7.0-20070801/configure\n",
            "mecab-ipadic-2.7.0-20070801/configure.in\n",
            "mecab-ipadic-2.7.0-20070801/install-sh\n",
            "mecab-ipadic-2.7.0-20070801/missing\n",
            "mecab-ipadic-2.7.0-20070801/mkinstalldirs\n",
            "mecab-ipadic-2.7.0-20070801/Adj.csv\n",
            "mecab-ipadic-2.7.0-20070801/Adnominal.csv\n",
            "mecab-ipadic-2.7.0-20070801/Adverb.csv\n",
            "mecab-ipadic-2.7.0-20070801/Auxil.csv\n",
            "mecab-ipadic-2.7.0-20070801/Conjunction.csv\n",
            "mecab-ipadic-2.7.0-20070801/Filler.csv\n",
            "mecab-ipadic-2.7.0-20070801/Interjection.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.adjv.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.adverbal.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.demonst.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.nai.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.name.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.number.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.org.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.others.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.place.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.proper.csv\n",
            "mecab-ipadic-2.7.0-20070801/Noun.verbal.csv\n",
            "mecab-ipadic-2.7.0-20070801/Others.csv\n",
            "mecab-ipadic-2.7.0-20070801/Postp-col.csv\n",
            "mecab-ipadic-2.7.0-20070801/Postp.csv\n",
            "mecab-ipadic-2.7.0-20070801/Prefix.csv\n",
            "mecab-ipadic-2.7.0-20070801/Suffix.csv\n",
            "mecab-ipadic-2.7.0-20070801/Symbol.csv\n",
            "mecab-ipadic-2.7.0-20070801/Verb.csv\n",
            "mecab-ipadic-2.7.0-20070801/char.def\n",
            "mecab-ipadic-2.7.0-20070801/feature.def\n",
            "mecab-ipadic-2.7.0-20070801/left-id.def\n",
            "mecab-ipadic-2.7.0-20070801/matrix.def\n",
            "mecab-ipadic-2.7.0-20070801/pos-id.def\n",
            "mecab-ipadic-2.7.0-20070801/rewrite.def\n",
            "mecab-ipadic-2.7.0-20070801/right-id.def\n",
            "mecab-ipadic-2.7.0-20070801/unk.def\n",
            "mecab-ipadic-2.7.0-20070801/dicrc\n",
            "mecab-ipadic-2.7.0-20070801/RESULT\n",
            "[make-mecab-ipadic-NEologd] : Configure custom system dictionary on /content/mecab-ipadic-neologd/libexec/../build/mecab-ipadic-2.7.0-20070801-neologd-20200120\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for working aclocal-1.4... missing\n",
            "checking for working autoconf... missing\n",
            "checking for working automake-1.4... missing\n",
            "checking for working autoheader... missing\n",
            "checking for working makeinfo... missing\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking for mecab-config... /usr/bin/mecab-config\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "[make-mecab-ipadic-NEologd] : Encode the character encoding of system dictionary resources from EUC_JP to UTF-8\n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adnominal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Postp.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Others.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adj.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.verbal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.adverbal.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Symbol.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.demonst.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.proper.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.name.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Verb.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.adjv.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Postp-col.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Filler.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.org.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.nai.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Auxil.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.others.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Suffix.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Interjection.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Conjunction.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Adverb.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.number.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Prefix.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./Noun.place.csv \n",
            "rm ./Adnominal.csv \n",
            "rm ./Postp.csv \n",
            "rm ./Others.csv \n",
            "rm ./Adj.csv \n",
            "rm ./Noun.verbal.csv \n",
            "rm ./Noun.adverbal.csv \n",
            "rm ./Symbol.csv \n",
            "rm ./Noun.demonst.csv \n",
            "rm ./Noun.proper.csv \n",
            "rm ./Noun.name.csv \n",
            "rm ./Verb.csv \n",
            "rm ./Noun.adjv.csv \n",
            "rm ./Postp-col.csv \n",
            "rm ./Filler.csv \n",
            "rm ./Noun.org.csv \n",
            "rm ./Noun.csv \n",
            "rm ./Noun.nai.csv \n",
            "rm ./Auxil.csv \n",
            "rm ./Noun.others.csv \n",
            "rm ./Suffix.csv \n",
            "rm ./Interjection.csv \n",
            "rm ./Conjunction.csv \n",
            "rm ./Adverb.csv \n",
            "rm ./Noun.number.csv \n",
            "rm ./Prefix.csv \n",
            "rm ./Noun.place.csv \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./unk.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./right-id.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./feature.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./char.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./matrix.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./rewrite.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./pos-id.def \n",
            "./../../libexec/iconv_euc_to_utf8.sh ./left-id.def \n",
            "rm ./unk.def \n",
            "rm ./right-id.def \n",
            "rm ./feature.def \n",
            "rm ./char.def \n",
            "rm ./matrix.def \n",
            "rm ./rewrite.def \n",
            "rm ./pos-id.def \n",
            "rm ./left-id.def \n",
            "mv ./Noun.org.csv.utf8 ./Noun.org.csv \n",
            "mv ./Conjunction.csv.utf8 ./Conjunction.csv \n",
            "mv ./left-id.def.utf8 ./left-id.def \n",
            "mv ./Others.csv.utf8 ./Others.csv \n",
            "mv ./feature.def.utf8 ./feature.def \n",
            "mv ./Adj.csv.utf8 ./Adj.csv \n",
            "mv ./Interjection.csv.utf8 ./Interjection.csv \n",
            "mv ./Noun.name.csv.utf8 ./Noun.name.csv \n",
            "mv ./Noun.number.csv.utf8 ./Noun.number.csv \n",
            "mv ./rewrite.def.utf8 ./rewrite.def \n",
            "mv ./Adverb.csv.utf8 ./Adverb.csv \n",
            "mv ./Noun.place.csv.utf8 ./Noun.place.csv \n",
            "mv ./unk.def.utf8 ./unk.def \n",
            "mv ./Noun.proper.csv.utf8 ./Noun.proper.csv \n",
            "mv ./Postp-col.csv.utf8 ./Postp-col.csv \n",
            "mv ./char.def.utf8 ./char.def \n",
            "mv ./Prefix.csv.utf8 ./Prefix.csv \n",
            "mv ./Symbol.csv.utf8 ./Symbol.csv \n",
            "mv ./Noun.nai.csv.utf8 ./Noun.nai.csv \n",
            "mv ./Filler.csv.utf8 ./Filler.csv \n",
            "mv ./Noun.verbal.csv.utf8 ./Noun.verbal.csv \n",
            "mv ./Auxil.csv.utf8 ./Auxil.csv \n",
            "mv ./Postp.csv.utf8 ./Postp.csv \n",
            "mv ./matrix.def.utf8 ./matrix.def \n",
            "mv ./Noun.adverbal.csv.utf8 ./Noun.adverbal.csv \n",
            "mv ./Noun.adjv.csv.utf8 ./Noun.adjv.csv \n",
            "mv ./Adnominal.csv.utf8 ./Adnominal.csv \n",
            "mv ./Verb.csv.utf8 ./Verb.csv \n",
            "mv ./pos-id.def.utf8 ./pos-id.def \n",
            "mv ./Noun.others.csv.utf8 ./Noun.others.csv \n",
            "mv ./Noun.csv.utf8 ./Noun.csv \n",
            "mv ./Suffix.csv.utf8 ./Suffix.csv \n",
            "mv ./Noun.demonst.csv.utf8 ./Noun.demonst.csv \n",
            "mv ./right-id.def.utf8 ./right-id.def \n",
            "[make-mecab-ipadic-NEologd] : Fix yomigana field of IPA dictionary\n",
            "patching file Noun.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Verb.csv\n",
            "patching file Noun.verbal.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.adverbal.csv\n",
            "patching file Noun.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.org.csv\n",
            "patching file Noun.others.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Noun.verbal.csv\n",
            "patching file Prefix.csv\n",
            "patching file Suffix.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Noun.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.org.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Noun.verbal.csv\n",
            "patching file Noun.name.csv\n",
            "patching file Noun.org.csv\n",
            "patching file Noun.place.csv\n",
            "patching file Noun.proper.csv\n",
            "patching file Suffix.csv\n",
            "patching file Noun.demonst.csv\n",
            "patching file Noun.csv\n",
            "patching file Noun.name.csv\n",
            "[make-mecab-ipadic-NEologd] : Copy user dictionary resource\n",
            "[make-mecab-ipadic-NEologd] : Install adverb entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adverb-dict-seed.20150623.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install interjection entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-interjection-dict-seed.20170216.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install noun orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-common-noun-ortho-variant-dict-seed.20170228.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install noun orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-proper-noun-ortho-variant-dict-seed.20161110.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install entries of orthographic variant of a noun used as verb form using /content/mecab-ipadic-neologd/libexec/../seed/neologd-noun-sahen-conn-ortho-variant-dict-seed.20160323.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Install frequent adjective orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-std-dict-seed.20151126.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Not install /content/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-exp-dict-seed.20151126.csv.xz\n",
            "[make-mecab-ipadic-NEologd] :     When you install neologd-adjective-exp-dict-seed.20151126.csv.xz, please set --install_adjective_exp option\n",
            "\n",
            "[make-mecab-ipadic-NEologd] : Install adjective verb orthographic variant entries using /content/mecab-ipadic-neologd/libexec/../seed/neologd-adjective-verb-dict-seed.20160324.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Not install /content/mecab-ipadic-neologd/libexec/../seed/neologd-date-time-infreq-dict-seed.20190415.csv.xz\n",
            "[make-mecab-ipadic-NEologd] :     When you install neologd-date-time-infreq-dict-seed.20190415.csv.xz, please set --install_infreq_datetime option\n",
            "\n",
            "[make-mecab-ipadic-NEologd] : Not install /content/mecab-ipadic-neologd/libexec/../seed/neologd-quantity-infreq-dict-seed.20190415.csv.xz\n",
            "[make-mecab-ipadic-NEologd] :     When you install neologd-quantity-infreq-dict-seed.20190415.csv.xz, please set --install_infreq_quantity option\n",
            "\n",
            "[make-mecab-ipadic-NEologd] : Install entries of ill formed words using /content/mecab-ipadic-neologd/libexec/../seed/neologd-ill-formed-words-dict-seed.20170127.csv.xz\n",
            "[make-mecab-ipadic-NEologd] : Re-Index system dictionary\n",
            "reading ./unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "reading ./Adnominal.csv ... 135\n",
            "reading ./neologd-common-noun-ortho-variant-dict-seed.20170228.csv ... 152869\n",
            "reading ./Postp.csv ... 146\n",
            "reading ./Others.csv ... 2\n",
            "reading ./neologd-noun-sahen-conn-ortho-variant-dict-seed.20160323.csv ... 26058\n",
            "reading ./mecab-user-dict-seed.20200120.csv ... 3177392\n",
            "reading ./Adj.csv ... 27210\n",
            "reading ./Noun.verbal.csv ... 12150\n",
            "reading ./Noun.adverbal.csv ... 808\n",
            "reading ./Symbol.csv ... 208\n",
            "reading ./Noun.demonst.csv ... 120\n",
            "reading ./Noun.proper.csv ... 27493\n",
            "reading ./Noun.name.csv ... 34215\n",
            "reading ./Verb.csv ... 130750\n",
            "reading ./Noun.adjv.csv ... 3328\n",
            "reading ./neologd-ill-formed-words-dict-seed.20170127.csv ... 60616\n",
            "reading ./Postp-col.csv ... 91\n",
            "reading ./Filler.csv ... 19\n",
            "reading ./Noun.org.csv ... 17149\n",
            "reading ./Noun.csv ... 60734\n",
            "reading ./neologd-adjective-verb-dict-seed.20160324.csv ... 20268\n",
            "reading ./Noun.nai.csv ... 42\n",
            "reading ./neologd-adverb-dict-seed.20150623.csv ... 139792\n",
            "reading ./Auxil.csv ... 199\n",
            "reading ./neologd-adjective-std-dict-seed.20151126.csv ... 507812\n",
            "reading ./Noun.others.csv ... 153\n",
            "reading ./neologd-proper-noun-ortho-variant-dict-seed.20161110.csv ... 138379\n",
            "reading ./Suffix.csv ... 1448\n",
            "reading ./Interjection.csv ... 252\n",
            "reading ./Conjunction.csv ... 171\n",
            "reading ./Adverb.csv ... 3032\n",
            "reading ./neologd-interjection-dict-seed.20170216.csv ... 4701\n",
            "reading ./Noun.number.csv ... 42\n",
            "reading ./Prefix.csv ... 224\n",
            "reading ./Noun.place.csv ... 73194\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1316x1316\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "[make-mecab-ipadic-NEologd] : Make custom system dictionary on /content/mecab-ipadic-neologd/libexec/../build/mecab-ipadic-2.7.0-20070801-neologd-20200120\n",
            "make: Nothing to be done for 'all'.\n",
            "[make-mecab-ipadic-NEologd] : Finish..\n",
            "[install-mecab-ipadic-NEologd] : Get results of tokenize test\n",
            "[test-mecab-ipadic-NEologd] : Start..\n",
            "[test-mecab-ipadic-NEologd] : Replace timestamp from 'git clone' date to 'git commit' date\n",
            "[test-mecab-ipadic-NEologd] : Get buzz phrases\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1332  100  1332    0     0    890      0  0:00:01  0:00:01 --:--:--   889\n",
            "[test-mecab-ipadic-NEologd] : Get difference between default system dictionary and mecab-ipadic-NEologd\n",
            "[test-mecab-ipadic-NEologd] : Tokenize phrase using default system dictionary\n",
            "[test-mecab-ipadic-NEologd] : Tokenize phrase using mecab-ipadic-NEologd\n",
            "[test-mecab-ipadic-NEologd] : Get result of diff\n",
            "[test-mecab-ipadic-NEologd] : Please check difference between default system dictionary and mecab-ipadic-NEologd\n",
            "\n",
            "default system dictionary\t  |\tmecab-ipadic-NEologd\n",
            "ギャラ ドス \t\t\t  |\tギャラドス \n",
            "健康 保険 \t\t\t  |\t健康保険 \n",
            "ドナウ デルタ \t\t\t  |\tドナウデルタ \n",
            "ノーマン 湖 \t\t\t  |\tノー マン湖 \n",
            "岡山 シーガルズ \t\t  |\t岡山シーガルズ \n",
            "\n",
            "[test-mecab-ipadic-NEologd] : Finish..\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Please check the list of differences in the upper part.\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Do you want to install mecab-ipadic-NEologd? Type yes or no.\n",
            "[install-mecab-ipadic-NEologd] : OK. Let's install mecab-ipadic-NEologd.\n",
            "[install-mecab-ipadic-NEologd] : Start..\n",
            "[install-mecab-ipadic-NEologd] : /usr/lib/x86_64-linux-gnu/mecab/dic isn't current user's directory\n",
            "[install-mecab-ipadic-NEologd] : Sudo make install to /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            "make[1]: Entering directory '/content/mecab-ipadic-neologd/build/mecab-ipadic-2.7.0-20070801-neologd-20200120'\n",
            "make[1]: Nothing to be done for 'install-exec-am'.\n",
            "/bin/bash ./mkinstalldirs /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            "mkdir /usr/lib/x86_64-linux-gnu/mecab\n",
            "mkdir /usr/lib/x86_64-linux-gnu/mecab/dic\n",
            "mkdir /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            " /usr/bin/install -c -m 644 ./matrix.bin /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/matrix.bin\n",
            " /usr/bin/install -c -m 644 ./char.bin /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/char.bin\n",
            " /usr/bin/install -c -m 644 ./sys.dic /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/sys.dic\n",
            " /usr/bin/install -c -m 644 ./unk.dic /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/unk.dic\n",
            " /usr/bin/install -c -m 644 ./left-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/left-id.def\n",
            " /usr/bin/install -c -m 644 ./right-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/right-id.def\n",
            " /usr/bin/install -c -m 644 ./rewrite.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/rewrite.def\n",
            " /usr/bin/install -c -m 644 ./pos-id.def /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/pos-id.def\n",
            " /usr/bin/install -c -m 644 ./dicrc /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd/dicrc\n",
            "make[1]: Leaving directory '/content/mecab-ipadic-neologd/build/mecab-ipadic-2.7.0-20070801-neologd-20200120'\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Install completed.\n",
            "[install-mecab-ipadic-NEologd] : When you use MeCab, you can set '/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd' as a value of '-d' option of MeCab.\n",
            "[install-mecab-ipadic-NEologd] : Usage of mecab-ipadic-NEologd is here.\n",
            "Usage:\n",
            "    $ mecab -d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd ...\n",
            "\n",
            "[install-mecab-ipadic-NEologd] : Finish..\n",
            "[install-mecab-ipadic-NEologd] : Finish..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4blWbf8Mgowk",
        "colab_type": "code",
        "outputId": "a5a08838-88ed-4a45-b158-76fd75f7ad87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "!cat /etc/mecabrc "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ";\n",
            "; Configuration file of MeCab\n",
            ";\n",
            "; $Id: mecabrc.in,v 1.3 2006/05/29 15:36:08 taku-ku Exp $;\n",
            ";\n",
            "dicdir = /var/lib/mecab/dic/debian\n",
            "\n",
            "; userdic = /home/foo/bar/user.dic\n",
            "\n",
            "; output-format-type = wakati\n",
            "; input-buffer-size = 8192\n",
            "\n",
            "; node-format = %m\\n\n",
            "; bos-format = %S\\n\n",
            "; eos-format = EOS\\n\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwpmKb8xgpUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sed -e \"s!/var/lib/mecab/dic/debian!/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd!g\" /etc/mecabrc > /etc/mecabrc.new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xiLzllnguu0",
        "colab_type": "code",
        "outputId": "49cc525d-16b7-471e-c380-181b23ddde20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "!cat /etc/mecabrc.new\n",
        "!cp /etc/mecabrc /etc/mecabrc.org\n",
        "!cp /etc/mecabrc.new /etc/mecabrc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ";\n",
            "; Configuration file of MeCab\n",
            ";\n",
            "; $Id: mecabrc.in,v 1.3 2006/05/29 15:36:08 taku-ku Exp $;\n",
            ";\n",
            "dicdir = /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd\n",
            "\n",
            "; userdic = /home/foo/bar/user.dic\n",
            "\n",
            "; output-format-type = wakati\n",
            "; input-buffer-size = 8192\n",
            "\n",
            "; node-format = %m\\n\n",
            "; bos-format = %S\\n\n",
            "; eos-format = EOS\\n\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6uf0nb7g2kk",
        "colab_type": "code",
        "outputId": "9efede0e-63b3-4aca-ca6a-658f5c28fdc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        }
      },
      "source": [
        "!apt-get -q -y install swig "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  swig3.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig3.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 1,100 kB of archives.\n",
            "After this operation, 5,822 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Fetched 1,100 kB in 0s (9,390 kB/s)\n",
            "Selecting previously unselected package swig3.0.\n",
            "(Reading database ... 135222 files and directories currently installed.)\n",
            "Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig (3.0.12-1) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Setting up swig (3.0.12-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pShZR5yg4OD",
        "colab_type": "code",
        "outputId": "4e3e0aa9-ba67-4479-ff64-35f468fd1751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "!pip install mecab-python3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mecab-python3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/c5/acaa5eeb3f61a98cf31d8aacbbbf23f3e1c9eadfe6e2d508add82e7e9039/mecab_python3-0.996.3-cp36-cp36m-manylinux2010_x86_64.whl (17.1MB)\n",
            "\u001b[K     |████████████████████████████████| 17.1MB 244kB/s \n",
            "\u001b[?25hInstalling collected packages: mecab-python3\n",
            "Successfully installed mecab-python3-0.996.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAqUnaYl-qRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AIrP6Sh-2HT",
        "colab_type": "code",
        "outputId": "24b24d4d-662d-4ad8-b7c3-c75f4600e333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "# 日本語対応のため\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format(\n",
        "    './data/entity_vector/entity_vector.model.bin', binary=True)\n",
        "\n",
        "model.wv.save_word2vec_format('./data/japanese_word2vec_vectors.vec')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_UkT2qV-1Pq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zcPkvkK_I4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.vocab import Vectors\n",
        "\n",
        "japanese_word2vec_vectors = Vectors(\n",
        "    name='./data/japanese_word2vec_vectors.vec')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNQeeTPjhCBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pytorch でdataloaderがわかりやすい\n",
        "import glob\n",
        "import os\n",
        "import io\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import spacy\n",
        "import torchtext\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "\n",
        "\n",
        "def get_IMDb_DataLoaders_and_TEXT(max_length=256, batch_size=24):\n",
        "    \"\"\"IMDbのDataLoaderとTEXTオブジェクトを取得する。 \"\"\"\n",
        "\n",
        "    # 訓練データのtsvファイルを作成します\n",
        "    f = open('./data/IMDb_train.tsv', 'w')\n",
        "\n",
        "    path = './data/aclImdb/train/pos/'\n",
        "    for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "\n",
        "            # タブがあれば消しておきます\n",
        "            text = text.replace('\\t', \" \")\n",
        "\n",
        "            text = text+'\\t'+'1'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "\n",
        "    path = './data/aclImdb/train/neg/'\n",
        "    for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "\n",
        "            # タブがあれば消しておきます\n",
        "            text = text.replace('\\t', \" \")\n",
        "\n",
        "            text = text+'\\t'+'0'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "\n",
        "    f.close()\n",
        "\n",
        "   # テストデータの作成\n",
        "    f = open('./data/IMDb_test.tsv', 'w')\n",
        "\n",
        "    path = './data/aclImdb/test/pos/'\n",
        "    for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "\n",
        "            # タブがあれば消しておきます\n",
        "            text = text.replace('\\t', \" \")\n",
        "\n",
        "            text = text+'\\t'+'1'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "\n",
        "    path = './data/aclImdb/test/neg/'\n",
        "    for fname in glob.glob(os.path.join(path, '*.txt')):\n",
        "        with io.open(fname, 'r', encoding=\"utf-8\") as ff:\n",
        "            text = ff.readline()\n",
        "\n",
        "            # タブがあれば消しておきます\n",
        "            text = text.replace('\\t', \" \")\n",
        "\n",
        "            text = text+'\\t'+'0'+'\\t'+'\\n'\n",
        "            f.write(text)\n",
        "    f.close()\n",
        "\n",
        "    def preprocessing_text(text):\n",
        "        # 改行コードを消去\n",
        "        text = re.sub('<br />', '', text)\n",
        "\n",
        "        # カンマ、ピリオド以外の記号をスペースに置換\n",
        "        for p in string.punctuation:\n",
        "            if (p == \".\") or (p == \",\"):\n",
        "                continue\n",
        "            else:\n",
        "                text = text.replace(p, \" \")\n",
        "\n",
        "        # ピリオドなどの前後にはスペースを入れておく\n",
        "        text = text.replace(\".\", \" . \")\n",
        "        text = text.replace(\",\", \" , \")\n",
        "        return text\n",
        "\n",
        "    # 分かち書き（今回はデータが英語で、簡易的にスペースで区切る）\n",
        "    def tokenizer_punctuation(text):\n",
        "        return text.strip().split()\n",
        "\n",
        "\n",
        "    # 前処理と分かち書きをまとめた関数を定義\n",
        "    def tokenizer_with_preprocessing(text):\n",
        "        text = preprocessing_text(text)\n",
        "        ret = tokenizer_punctuation(text)\n",
        "        return ret\n",
        "\n",
        "\n",
        "    # データを読み込んだときに、読み込んだ内容に対して行う処理を定義します\n",
        "    # max_length\n",
        "    TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, use_vocab=True,\n",
        "                                lower=True, include_lengths=True, batch_first=True, fix_length=max_length, init_token=\"<cls>\", eos_token=\"<eos>\")\n",
        "    LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "    # フォルダ「data」から各tsvファイルを読み込みます\n",
        "    train_val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
        "        path='./data/', train='IMDb_train.tsv',\n",
        "        test='IMDb_test.tsv', format='tsv',\n",
        "        fields=[('Text', TEXT), ('Label', LABEL)])\n",
        "\n",
        "    # torchtext.data.Datasetのsplit関数で訓練データとvalidationデータを分ける\n",
        "    train_ds, val_ds = train_val_ds.split(\n",
        "        split_ratio=0.8, random_state=random.seed(1234))\n",
        "\n",
        "    # torchtextで単語ベクトルとして英語学習済みモデルを読み込みます\n",
        "    english_fasttext_vectors = Vectors(name='data/wiki-news-300d-1M.vec')\n",
        "\n",
        "    # ベクトル化したバージョンのボキャブラリーを作成します\n",
        "    TEXT.build_vocab(train_ds, vectors=english_fasttext_vectors, min_freq=10)\n",
        "\n",
        "    # DataLoaderを作成します（torchtextの文脈では単純にiteraterと呼ばれています）\n",
        "    train_dl = torchtext.data.Iterator(\n",
        "        train_ds, batch_size=batch_size, train=True)\n",
        "\n",
        "    val_dl = torchtext.data.Iterator(\n",
        "        val_ds, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "    test_dl = torchtext.data.Iterator(\n",
        "        test_ds, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "    return train_dl, val_dl, test_dl, TEXT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOs6P0wetJuK",
        "colab_type": "text"
      },
      "source": [
        "fastText\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jskOEIhqtF2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.vocab import Vectors\n",
        "\n",
        "japanese_fasttext_vectors = Vectors(name='./data/vector_neologd/model.vec')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTWV3sDo2S_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext\n",
        "\n",
        "\n",
        "# 文章とラベルの両方に用意します\n",
        "max_length = 256\n",
        "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, use_vocab=True,\n",
        "                            lower=True, include_lengths=True, batch_first=True, fix_length=max_length, init_token=\"<cls>\", eos_token=\"<eos>\")\n",
        "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5D0ukpX2XwC",
        "colab_type": "code",
        "outputId": "9e716d54-3a6e-4a1d-b467-33f0f98359dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "train_val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
        "    path='./data/', train='IMDb_train.tsv',\n",
        "    test='IMDb_test.tsv', format='tsv',\n",
        "    fields=[('Text', TEXT), ('Label', LABEL)])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "訓練および検証のデータ数 25000\n",
            "1つ目の訓練および検証のデータ {'Text': ['the', 'performances', 'in', 'this', 'movie', 'were', 'fantastic', '.', 'the', 'dialogue', 'was', 'great', '.', 'jason', 'patric', 'delivered', 'a', 'fantastic', 'performance', 'as', 'kid', 'collins', 'in', 'this', 'wonderful', 'adaptation', 'of', 'the', 'jim', 'thompson', 'novel', '.', 'far', 'superior', 'to', 'the', 'grifters', ',', 'which', 'was', 'a', 'good', 'movie', ',', 'this', 'film', 'really', 'stayed', 'true', 'to', 'the', 'pulp', 'fiction', 'film', 'noir', 'roots', 'from', 'which', 'the', 'story', 'came', '.', 'i', 'recommend', 'this', 'movie', 'to', 'all', 'film', 'noir', 'fans', '.'], 'Label': '1'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i057Xd7-2coY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 英語用\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "english_fasttext_vectors = Vectors(name='data/wiki-news-300d-1M.vec')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShwLxfj-27t_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torchtext\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBlJGJWJ3Qek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup seeds\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5E9Bd9n3Tvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# わかりやすいTransformer\n",
        "class Embedder(nn.Module):\n",
        "    '''idで示されている単語をベクトルに変換します'''\n",
        "\n",
        "    def __init__(self, text_embedding_vectors):\n",
        "        super(Embedder, self).__init__()\n",
        "\n",
        "        self.embeddings = nn.Embedding.from_pretrained(\n",
        "            embeddings=text_embedding_vectors, freeze=True)\n",
        "        # freeze=Trueによりバックプロパゲーションで更新されず変化しなくなります\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_vec = self.embeddings(x)\n",
        "\n",
        "        return x_vec\n",
        "\n",
        "\n",
        "class PositionalEncoder(nn.Module):\n",
        "    '''入力された単語の位置を示すベクトル情報を付加する'''\n",
        "\n",
        "    def __init__(self, d_model=300, max_seq_len=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model  # 単語ベクトルの次元数\n",
        "\n",
        "        # 単語の順番（pos）と埋め込みベクトルの次元の位置（i）によって一意に定まる値の表をpeとして作成\n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "\n",
        "        # GPUが使える場合はGPUへ送る\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        pe = pe.to(device)\n",
        "\n",
        "        for pos in range(max_seq_len):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
        "                pe[pos, i + 1] = math.cos(pos /\n",
        "                                          (10000 ** ((2 * (i + 1))/d_model)))\n",
        "\n",
        "        # 表peの先頭に、ミニバッチ次元となる次元を足す\n",
        "        self.pe = pe.unsqueeze(0)\n",
        "\n",
        "        # 勾配を計算しないようにする\n",
        "        self.pe.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # 入力xとPositonal Encodingを足し算する\n",
        "        # xがpeよりも小さいので、大きくする\n",
        "        ret = math.sqrt(self.d_model)*x + self.pe\n",
        "        return ret\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    '''Transformerは本当はマルチヘッドAttentionですが、\n",
        "    分かりやすさを優先しシングルAttentionで実装します'''\n",
        "\n",
        "    def __init__(self, d_model=300):\n",
        "        super().__init__()\n",
        "\n",
        "        # SAGANでは1dConvを使用したが、今回は全結合層で特徴量を変換する\n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # 出力時に使用する全結合層\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "\n",
        "        # Attentionの大きさ調整の変数\n",
        "        self.d_k = d_model\n",
        "\n",
        "    def forward(self, q, k, v, mask):\n",
        "        # 全結合層で特徴量を変換\n",
        "        k = self.k_linear(k)\n",
        "        q = self.q_linear(q)\n",
        "        v = self.v_linear(v)\n",
        "\n",
        "        # Attentionの値を計算する\n",
        "        # 各値を足し算すると大きくなりすぎるので、root(d_k)で割って調整\n",
        "        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)\n",
        "\n",
        "        # ここでmaskを計算\n",
        "        mask = mask.unsqueeze(1)\n",
        "        weights = weights.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # softmaxで規格化をする\n",
        "        normlized_weights = F.softmax(weights, dim=-1)\n",
        "\n",
        "        # AttentionをValueとかけ算\n",
        "        output = torch.matmul(normlized_weights, v)\n",
        "\n",
        "        # 全結合層で特徴量を変換\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, normlized_weights\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
        "        '''Attention層から出力を単純に全結合層2つで特徴量を変換するだけのユニットです'''\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear_1(x)\n",
        "        x = self.dropout(F.relu(x))\n",
        "        x = self.linear_2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # LayerNormalization層\n",
        "        # https://pytorch.org/docs/stable/nn.html?highlight=layernorm\n",
        "        self.norm_1 = nn.LayerNorm(d_model)\n",
        "        self.norm_2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Attention層\n",
        "        self.attn = Attention(d_model)\n",
        "\n",
        "        # Attentionのあとの全結合層2つ\n",
        "        self.ff = FeedForward(d_model)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # 正規化とAttention\n",
        "        x_normlized = self.norm_1(x)\n",
        "        output, normlized_weights = self.attn(\n",
        "            x_normlized, x_normlized, x_normlized, mask)\n",
        "\n",
        "        x2 = x + self.dropout_1(output)\n",
        "\n",
        "        # 正規化と全結合層\n",
        "        x_normlized2 = self.norm_2(x2)\n",
        "        output = x2 + self.dropout_2(self.ff(x_normlized2))\n",
        "\n",
        "        return output, normlized_weights\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    '''Transformer_Blockの出力を使用し、最後にクラス分類させる'''\n",
        "\n",
        "    def __init__(self, d_model=300, output_dim=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # 全結合層\n",
        "        self.linear = nn.Linear(d_model, output_dim)  # output_dimはポジ・ネガの2つ\n",
        "\n",
        "        # 重み初期化処理\n",
        "        nn.init.normal_(self.linear.weight, std=0.02)\n",
        "        nn.init.normal_(self.linear.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = x[:, 0, :]  # 各ミニバッチの各文の先頭の単語の特徴量（300次元）を取り出す\n",
        "        out = self.linear(x0)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "# 最終的なTransformerモデルのクラス\n",
        "\n",
        "\n",
        "class TransformerClassification(nn.Module):\n",
        "    '''Transformerでクラス分類させる'''\n",
        "\n",
        "    def __init__(self, text_embedding_vectors, d_model=300, max_seq_len=256, output_dim=2):\n",
        "        super().__init__()\n",
        "\n",
        "        # モデル構築\n",
        "        self.net1 = Embedder(text_embedding_vectors)\n",
        "        self.net2 = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
        "        self.net3_1 = TransformerBlock(d_model=d_model)\n",
        "        self.net3_2 = TransformerBlock(d_model=d_model)\n",
        "        self.net4 = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x1 = self.net1(x)  # 単語をベクトルに\n",
        "        x2 = self.net2(x1)  # Positon情報を足し算\n",
        "        x3_1, normlized_weights_1 = self.net3_1(\n",
        "            x2, mask)  # Self-Attentionで特徴量を変換\n",
        "        x3_2, normlized_weights_2 = self.net3_2(\n",
        "            x3_1, mask)  # Self-Attentionで特徴量を変換\n",
        "        x4 = self.net4(x3_2)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
        "        return x4, normlized_weights_1, normlized_weights_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAbzdc4z7tsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl, val_dl, test_dl, TEXT = get_IMDb_DataLoaders_and_TEXT(\n",
        "    max_length=256, batch_size=64)\n",
        "\n",
        "dataloaders_dict = {\"train\": train_dl, \"val\": val_dl}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIcdipT7C7I_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        if isinstance(alpha,(float,int,long)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
        "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        if input.dim()>2:\n",
        "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
        "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
        "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
        "        target = target.view(-1,1)\n",
        "\n",
        "        logpt = F.log_softmax(input)\n",
        "        logpt = logpt.gather(1,target)\n",
        "        logpt = logpt.view(-1)\n",
        "        pt = Variable(logpt.data.exp())\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            if self.alpha.type()!=input.data.type():\n",
        "                self.alpha = self.alpha.type_as(input.data)\n",
        "            at = self.alpha.gather(0,target.data.view(-1))\n",
        "            logpt = logpt * Variable(at)\n",
        "\n",
        "        loss = -1 * (1-pt)**self.gamma * logpt\n",
        "        if self.size_average: return loss.mean()\n",
        "        else: return loss.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTB_Wgq1AXEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imbalanceデータに対してはfocal loss or クラスの数の逆数をかける\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#criterion = FocalLoss()\n",
        "\n",
        "learning_rate = 2e-5\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x2SA4pz3WfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "    print('-----start-------')\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モードに\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for batch in (dataloaders_dict[phase]):\n",
        "                # batchはTextとLableの辞書オブジェクト\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                inputs = batch.Text[0].to(device)  # 文章\n",
        "                labels = batch.Label.to(device)  # ラベル\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "\n",
        "                    # mask作成\n",
        "                    input_pad = 1  # 単語のIDにおいて、'<pad>': 1 なので\n",
        "                    input_mask = (inputs != input_pad)\n",
        "\n",
        "                    # Transformerに入力\n",
        "                    outputs, _, _ = net(inputs, input_mask)\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # 結果の計算\n",
        "                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n",
        "                    # 正解数の合計を更新\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('Epoch {}/{} | {:^5} |  Loss: {:.4f} Acc: {:.4f}'.format(epoch+1, num_epochs,\n",
        "                                                                           phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoESvrTCAtw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 20\n",
        "net_trained = train_model(net, dataloaders_dict,\n",
        "                          criterion, optimizer, num_epochs=num_epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUusZ0YY7l7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Attentionの可視化\n",
        "def highlight(word, attn):\n",
        "    \"Attentionの値が大きいと文字の背景が濃い赤になるhtmlを出力させる関数\"\n",
        "\n",
        "    html_color = '#%02X%02X%02X' % (\n",
        "        255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
        "    return '<span style=\"background-color: {}\"> {}</span>'.format(html_color, word)\n",
        "\n",
        "\n",
        "def mk_html(index, batch, preds, normlized_weights_1, normlized_weights_2, TEXT):\n",
        "    \"HTMLデータを作成する\"\n",
        "\n",
        "    # indexの結果を抽出\n",
        "    sentence = batch.Text[0][index]  # 文章\n",
        "    label = batch.Label[index]  # ラベル\n",
        "    pred = preds[index]  # 予測\n",
        "\n",
        "    # indexのAttentionを抽出と規格化\n",
        "    attens1 = normlized_weights_1[index, 0, :]  # 0番目の<cls>のAttention\n",
        "    attens1 /= attens1.max()\n",
        "\n",
        "    attens2 = normlized_weights_2[index, 0, :]  # 0番目の<cls>のAttention\n",
        "    attens2 /= attens2.max()\n",
        "\n",
        "    # ラベルと予測結果を文字に置き換え\n",
        "    if label == 0:\n",
        "        label_str = \"Negative\"\n",
        "    else:\n",
        "        label_str = \"Positive\"\n",
        "\n",
        "    if pred == 0:\n",
        "        pred_str = \"Negative\"\n",
        "    else:\n",
        "        pred_str = \"Positive\"\n",
        "\n",
        "    # 表示用のHTMLを作成する\n",
        "    html = '正解ラベル：{}<br>推論ラベル：{}<br><br>'.format(label_str, pred_str)\n",
        "\n",
        "    # 1段目のAttention\n",
        "    html += '[TransformerBlockの1段目のAttentionを可視化]<br>'\n",
        "    for word, attn in zip(sentence, attens1):\n",
        "        html += highlight(TEXT.vocab.itos[word], attn)\n",
        "    html += \"<br><br>\"\n",
        "\n",
        "    # 2段目のAttention\n",
        "    html += '[TransformerBlockの2段目のAttentionを可視化]<br>'\n",
        "    for word, attn in zip(sentence, attens2):\n",
        "        html += highlight(TEXT.vocab.itos[word], attn)\n",
        "\n",
        "    html += \"<br><br>\"\n",
        "\n",
        "    return html"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}